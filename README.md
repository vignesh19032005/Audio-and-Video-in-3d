# 🎥🎶 3D Audio & Video Data Visualization

> **Understanding how machines "see" and "hear" data in a 3D space!**

## 🚀 Overview

This project explores how **audio and video data** can be transformed into **3D visualizations** to better understand how machines process sensory input. By mapping **video frames** into 3D meshes and **audio waves** into interactive 3D spectrograms, we can gain a new perspective on machine perception. 🔍💡

## ✨ Features

- 🎬 **Video Frame to 3D Mesh** – Converts video pixels into 3D point clouds.
- 🎧 **Audio Wave to 3D Spectrogram** – Uses FFT to transform sound waves into a dynamic 3D visualization.
- 🔄 **Real-time Interactivity** – Rotate, zoom, and explore data in a 3D space.
- ⚡ **High-Performance Processing** – Optimized using OpenGL and efficient data handling techniques.

## 📌 Tech Stack

- **Python** 🐍
- **OpenGL** 🎨
- **Pygame** 🎮
- **PyDub** 🎼
- **OpenCV (CV2)** 📷
- **NumPy** 🔢

## 🛠 Installation

1. **Clone the repository**:
   ```bash
   git clone [https://github.com/vignesh19032005/3D-Audio-Video-Visualization.git](https://github.com/vignesh19032005/Audio-and-Video-in-3d.git)
   cd 3D-Audio-Video-Visualization
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

## 🚀 Usage

1. **Run the video visualization**:
   ```bash
   python Video_to_3D.py --input video.mp4
   ```
2. **Run the audio visualization**:
   ```bash
   python Audio_to_3D.py --input audio.wav
   ```

## 🎯 Future Enhancements

- 🎵 Support for real-time microphone audio visualization.
- 🎬 Live camera feed transformation into 3D data.
- ⚡ Performance optimization for handling large datasets.

## 🙌 Contribution

Feel free to **fork** this repository, open issues, or submit pull requests! 🚀

## 📝 License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---

💡 *Inspired by the idea of giving AI its own vision and hearing senses!* 🤖👁️🎶
